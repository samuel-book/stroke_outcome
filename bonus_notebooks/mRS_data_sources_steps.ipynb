{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06435bfe-d908-4a16-979b-1dace50522b7",
   "metadata": {},
   "source": [
    "# Derivation of mRS distributions from reference data\n",
    "\n",
    "This document calculates the modified Rankin Scale (mRS) distributions used in the stroke outcome modelling.\n",
    "\n",
    "## Plain English summary:\n",
    "\n",
    "The modified Rankin Scale is used to assign a level of disability to a patient who has had a stroke. When looking at the mRS scores of a whole population, some scores are more likely to occur than others depending on who is included in that population. For example, generally you might expect a large group of people to be given lower mRS scores (for lower levels of disability) before a stroke. After a stroke, the level of disability should increase and the group should contain more people with higher mRS scores. We can look at the proportion of people with each mRS score as the _probability_ of having that mRS score.\n",
    "\n",
    "The main aim of the stroke outcome model is to be able to predict the range of mRS scores of various different populations. We would like to know the expected mRS scores of groups of people before a stroke, people who received no treatment for their stroke, and people who were treated at any chosen time after their stroke began. There is no real-life data for this last group of people. However we can create a model that creates that data by combining other real-life datasets. The real-life datasets come from various clinical trials.\n",
    "\n",
    "We assume that the mRS scores of people after stroke depend on their time to treatment. The more time that passes between the start of the stroke and the treatment, the more likely it is that people will have higher disability scores. This continues up until a _time of no effect_ where the patients cannot benefit from the treatment but still run the risks of death due to the treatment.\n",
    "\n",
    "This document shows how to combine the real-life datasets to create mRS distributions that will be used everywhere in the stroke outcome model.\n",
    "\n",
    "The final datasets will cover these three main groups of people:\n",
    "+ Patients with a non-Large-Vessel Occlusion (nLVO) who were treated with intravenous thrombolysis (IVT).\n",
    "+ Patients with a Large-Vessel Occlusion (LVO) who were treated with intravenous thrombolysis (IVT).\n",
    "+ Patients with a Large-Vessel Occlusion (LVO) who were treated with mechanical thrombectomy (MT).\n",
    "\n",
    "## General method\n",
    "\n",
    "This document runs through the following steps in more detail.\n",
    "\n",
    "The steps to create the mRS distributions are:\n",
    "1. Find the mRS distributions of populations before their stroke.\n",
    "   + These data are available in the SSNAP data.\n",
    "   + We split the full cohort of patients into nLVO and LVO based on their NIHSS score.\n",
    "2. Find the mRS distributions of populations that received no treatment.\n",
    "   + This data is available for two groups. The first group is patients with LVOs. The second group is a mix of patients with nLVOs and patients with LVOs.\n",
    "   + We combine the groups and pick out only the patients with nLVO.\n",
    "3. Find the mRS distributions of populations that were treated after the time of no effect.\n",
    "   + At the time of no effect, we assume that patients given the treatment will see no benefit but still run the risk of death.\n",
    "   + We take the distributions for populations that received no treatment and adjust them for this excess death rate.\n",
    "4. Find the mRS distributions of populations that were treated at time zero.\n",
    "   + We take a reference data point at time zero and the mRS distributions at the time with no effect.\n",
    "   + Plugging these into a formula for the changing probability of each mRS score with time lets us find the probability distributions to time zero.\n",
    "\n",
    "The resulting mRS distributions are then saved for future use.\n",
    "\n",
    "## Related documents\n",
    "\n",
    "There are lots of details that go into calculating the mRS distributions and this document would become far too long if everything were contained here.\n",
    "\n",
    "The following details are calculated in the linked documents:  __TO DO: ADD LINKS__\n",
    "+ Excess deaths due to IVT.\n",
    "+ Excess deaths due to MT.\n",
    "+ Derivation of the formula for probability at time zero.\n",
    "\n",
    "## Summary of data sources\n",
    "\n",
    "The following image shows a flowchart summary of which data sources are used to create each mRS distribution.\n",
    "\n",
    "![An image showing a box for each derived mRS distribution. Arrows are drawn to each mRS distribution box from boxes containing each data source.](./images/data_sources_derivation_grid_noheaders_small.png)\n",
    "\n",
    "The following summary contains the same information with the addition of the actual mRS distribution values and of several images. The images show the exact parts of each paper or data source that contain the reference data, and those images are used throughout the rest of this document.\n",
    "\n",
    "![An image showing tables of the final derived mRS distributions. Around the tables there are inset images of data sources and a brief description of each. A large amount of arrows connect the data sources to the specific mRS distributions that they were used for.](./images/data_sources_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157787d1-567c-4f16-8aba-28755575d1e0",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "434d6849-54f7-4804-b026-3ee035936d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8cd5b-e6f9-4b4a-be9f-e0cda108a2e1",
   "metadata": {},
   "source": [
    "Store the derived mRS distributions in this dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd0fa9f-97e9-416c-8e34-8225bfee69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d034d-59a4-4c17-a077-30f41c719c05",
   "metadata": {},
   "source": [
    "The following function is used to fix rounding errors. All of the derived mRS distributions will be given to 3 decimal places, but rounding the data to this from a higher precision can sometimes cause the final distribution to not sum to 1.\n",
    "\n",
    "The basic steps of the function are:\n",
    "1. Add together the values to 3 decimal places. The sum should be less than 1 exactly.\n",
    "2. Look at the 4th digit of each number. Starting with the largest 4th digit, round up the three-decimal-place part to the next value.\n",
    "3. Continue rounding up until the sum is 1 exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693ded5-bf9b-475f-be2f-1f169ab1d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculations import fudge_sum_one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075e1f7-9df1-480d-90ed-1cecfc2e21db",
   "metadata": {},
   "source": [
    "## 1. Pre-stroke data\n",
    "\n",
    "![Method for finding the pre-stroke mRS distributions. 1. Collect data. Take SAMueL-1 survey data for patients with ischaemic stroke only. The data includes pre-stroke mRS scores. 2. Split into nLVO and LVO. Split the data into two groups using the NIHSS scale cutoff: LVO with NIHSS greater than 10 (>=11); nLVO with NIHSS of 10 or less (< 11). 3. Find the proportions of each group with each mRS score. → Result: nLVO pre-stroke and LVO pre-stroke mRS distributions.](images/data_sources_pre-stroke.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15127bf-dbf6-466d-b4b6-f460a69dd6af",
   "metadata": {},
   "source": [
    "Copy the values directly from the SAMueL-1 survey data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253b73c5-a21c-4265-aad1-eaab6030b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_stroke_nlvo = np.array(\n",
    "    [0.582771, 0.163513, 0.103988, 0.101109, 0.041796, 0.006822, 0.0000])\n",
    "pre_stroke_lvo = np.array(\n",
    "    [0.407796, 0.143538, 0.120133, 0.166050, 0.118023, 0.044460, 0.0000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84193a-486e-4a39-b418-bfc30846e4c2",
   "metadata": {},
   "source": [
    "Round to 3 decimal places and force sum to be exactly 1 by nudging the smallest fractions down or the largest fractions up as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478cf299-8270-48be-a8d8-1b7880137bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use append to make sure the mRS=6 value can't be changed.\n",
    "pre_stroke_nlvo = np.append(fudge_sum_one(pre_stroke_nlvo[:-1], dp=3), 0.0)\n",
    "pre_stroke_lvo = np.append(fudge_sum_one(pre_stroke_lvo[:-1], dp=3), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2cd181-ba0e-4f06-8f92-accfed0c5c14",
   "metadata": {},
   "source": [
    "Store the results in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dacc237-c6d8-46e2-aa0b-8b138a44c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['pre_stroke_nlvo'] = pre_stroke_nlvo\n",
    "mrs_dists['pre_stroke_lvo'] = pre_stroke_lvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37330c74-8708-4866-bfd2-e3bc4ad4db49",
   "metadata": {},
   "source": [
    "Show the results here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca8fb2d-2452-44e2-b4f7-ca8450c9b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.583 0.163 0.104 0.101 0.042 0.007 0.   ]\n",
      "[0.408 0.144 0.12  0.166 0.118 0.044 0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(mrs_dists['pre_stroke_nlvo'])\n",
    "print(mrs_dists['pre_stroke_lvo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf244174-7ccf-4d51-ba8f-e9b9f7f94a88",
   "metadata": {},
   "source": [
    "## 2. No treatment\n",
    "\n",
    "### LVO with no treatment\n",
    "\n",
    "![Method for finding mRS distributions for LVO with no treatment. 1. Collect data. Use the “Control population” set of data with no changes. → Result: LVO no treatment mRS distribution.](./images/data_sources_lvo-no-treatment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335ce80-34d6-4fd8-8280-3289716fec6b",
   "metadata": {},
   "source": [
    "Copy the values directly from the HERMES data and place them into the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ef313e-2d8d-4233-818a-62039d4ac6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['no_treatment_lvo'] = np.array([\n",
    "    0.050, 0.079, 0.136, 0.164, 0.247, 0.135, 0.189])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49899195-1967-4fd1-839f-4b1888575cd2",
   "metadata": {},
   "source": [
    "Check that the values sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b521f16-3b15-45ff-a615-aaa4f8640016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mrs_dists['no_treatment_lvo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64221704-1db7-470e-befd-09d214a45e04",
   "metadata": {},
   "source": [
    "### nLVO with no treatment\n",
    "\n",
    "![Method for finding mRS distribution for nLVO with no treatment. 1. Collect data. The sizes of the bars are not given in the text. Measure the number of pixels in each section of each “Placebo” bar in the image. Combine the bars and scale so that they sum to 1. → Result: combined nLVO & LVO no treatment mRS distribution. 2. Find a reference probability. The proportion 727 out of 1573 is 46%. → Probability P(mRS<=1)=0.46. 3. Remove the LVO patients. To reach P(mRS<=1)=0.46 in the nLVO-only distribution, use the following weighted distributions: Scale the “nLVO & LVO” distribution up to 149%. Scale the “LVO” distribution down to 49%. Take the difference to leave only the “nLVO” patients. → Result: mRS distribution for nLVO with no treatment.](./images/data_sources_nlvo-no-treatment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab24104-3f2f-4426-8e45-8124c6a60bd1",
   "metadata": {},
   "source": [
    "__1. Collect data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dfac74f-1459-46f9-a46c-49c6046f258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_treatment_nlvo_lvo = np.array(\n",
    "    [0.1486, 0.2022, 0.1253, 0.1397, 0.1806, 0.0861, 0.1175])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01dfe259-b7d2-49e4-b896-1c553e8d04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999 [0.149 0.202 0.125 0.14  0.181 0.086 0.117]\n"
     ]
    }
   ],
   "source": [
    "no_treatment_nlvo_lvo = fudge_sum_one(no_treatment_nlvo_lvo, dp=3)\n",
    "\n",
    "print(np.sum(no_treatment_nlvo_lvo), no_treatment_nlvo_lvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3b128-a704-4d3a-a749-2b6f6ec3a581",
   "metadata": {},
   "source": [
    "__2. Find a reference probability__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7637473a-a1af-4724-966a-abf26fd5b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mrsleq1_nlvo = 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adff333-0a5c-4e3b-82a9-4acf4a794c87",
   "metadata": {},
   "source": [
    "__3. Remove the LVO patients__\n",
    "\n",
    "Assume that the combined nLVO and LVO mRS distribution is made up of a weighted sum of a separate nLVO and LVO distribution.\n",
    "\n",
    "Define these probabilities for mRS <= 1: \n",
    "+ $P_1$ for nLVO & LVO,\n",
    "+ $P_2$ for LVO,\n",
    "+ $P_3$ for nLVO\n",
    "\n",
    "And calculate the weight $w$.\n",
    "\n",
    "The nLVO probability $P_3$ is found by:\n",
    "1. scaling up the combined nLVO & LVO distribution to $(1 + w)$\n",
    "1. scaling down the LVO distribution to $w$\n",
    "2. taking the difference\n",
    "\n",
    "As a formula, this is:\n",
    "\n",
    "$$ P_3 = (1 + w) \\times P_1 - w \\times P_2$$\n",
    "\n",
    "Rearrange to find the weight $w$:\n",
    "\n",
    "$$ w \\times (P_1 - P_2) = P_3 - P_1 $$\n",
    "\n",
    "$$ w = \\frac{P_3 - P_1}{P_1 - P_2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98417506-4573-4f06-a457-db22531d163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the probabilities of mRS=0 and mRS=1 in the no-treatment dist:\n",
    "p1 = np.sum(no_treatment_nlvo_lvo[:2])          # nLVO & LVO\n",
    "\n",
    "# Sum the probabilities of mRS=0 and mRS=1 in the no-treatment dist:\n",
    "p2 = np.sum(mrs_dists['no_treatment_lvo'][:2])  # LVO\n",
    "\n",
    "p3 = p_mrsleq1_nlvo                             # nLVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9728ca72-b73a-4c68-adcb-22436e16029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49099099099099125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (p3 - p1) / (p1 - p2)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da2817-4f4a-4c36-8864-08cb245d33cc",
   "metadata": {},
   "source": [
    "Use this weight to calculate the new distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d02f021c-cc53-4217-9a0b-4830893e737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19760811, 0.26239189, 0.1195991 , 0.12821622, 0.14859459,\n",
       "       0.06194144, 0.08164865])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_treatment_nlvo = (\n",
    "    ((1 + w) * no_treatment_nlvo_lvo) -\n",
    "    (w * mrs_dists['no_treatment_lvo'])\n",
    ")\n",
    "\n",
    "no_treatment_nlvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc0e1a-3b42-4f4b-959d-bc64f7f32a4e",
   "metadata": {},
   "source": [
    "Round to the same precision as the no-treatment LVO distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6625d53-109b-4a43-b10a-781b30f1103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.198 0.262 0.12  0.128 0.148 0.062 0.082]\n"
     ]
    }
   ],
   "source": [
    "no_treatment_nlvo = fudge_sum_one(no_treatment_nlvo, dp=3)\n",
    "\n",
    "print(np.round(np.sum(no_treatment_nlvo), 3), no_treatment_nlvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81e79c-13b0-482c-a93d-9e14efb74a7b",
   "metadata": {},
   "source": [
    "Store this result in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "680f16b9-5edb-4256-841e-c1d43723c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['no_treatment_nlvo'] = no_treatment_nlvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291bd8e7-add3-4b8a-b4d2-1b6d366a237e",
   "metadata": {},
   "source": [
    "Check that the mRS <= 1 values sum to the target probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "293b3d4b-95a9-4b51-b1ac-514d816c1e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mrs_dists['no_treatment_nlvo'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30112a-742b-494f-bce8-d2c96ad96a61",
   "metadata": {},
   "source": [
    "Are the values the same to a few decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d588bb5-889a-420b-8870-7b917f99cfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(np.sum(mrs_dists['no_treatment_nlvo'][:2]), p_mrsleq1_nlvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c11ad-dfb4-462f-abf1-52c77308bb6a",
   "metadata": {},
   "source": [
    "### Sanity check for nLVO with no treatment\n",
    "\n",
    "![Sanity check for the weights of splitting nLVO and LVO patients with no treatment. The weight used is 49%. We show that another weight 48% used in the IST-3 trial is close enough to the used weight. 1. Check Lees et al 2010 data. Number of patients in total is 3670. The nLVO/LVO split is not given. 2. Check IST-3 2012 data. Number of patients in total is 3035. Of these, 1464 have nLVO (NIHSS <= 10) and 1571 have LVO (NIHSS >= 11). → 51.7...% LVO, 48.2...% nLVO. 3. Check Emberson et al. 2014 data. Number of patients in total is 6756. Of these, 3199 have nLVO (NIHSS <= 10) and 3557 have LVO (NIHSS >= 11). → 52.6…% LVO, 47.3...% nLVO. The patients in Emberson are mostly made up of: 3035 from IST-3 + 3670 from Lees et al. 2010 = 6705 patients. → Expect the same nLVO/LVO split for Lees et al. 2010 as in IST-3. 4. Compare with derived split. 51% LVO, 49% nLVO – close enough to the above.](./images/data_sources_sanity_nlvo-lvo-split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9247c-25e8-4abe-a7cc-c554a7f4a619",
   "metadata": {},
   "source": [
    "## 3. Treatment at the no-effect time\n",
    "\n",
    "### nLVO treated with IVT at the no-effect time\n",
    "\n",
    "This step uses the excess death rate for IVT which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "![Method for finding mRS distribution for nLVO treated with IVT at the no-effect time. 1. Apply excess deaths to “no treatment” distribution. For a population treated at the time of no effect, expect no improvement compared with the no-treatment distribution but for some additional deaths. Assume excess death is equally likely for all patients. → Result: mRS distribution for nLVO treated with IVT at the no-effect time.](./images/data_sources_nlvo-ivt-no-effect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051f269-6622-45a6-ac10-1612f7fc79a1",
   "metadata": {},
   "source": [
    "Calculate the excess deaths by multiplying the no-treatment distribution by 0.011. Subtract the excess deaths from the mRS 0 to 5 bins, and add them on to the mRS=6 bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8845ad2f-88a9-4b13-b630-1f3a5b5234cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_effect_nlvo_ivt_deaths = np.append(\n",
    "    mrs_dists['no_treatment_nlvo'][:-1] * (1.0 - 0.011),\n",
    "    mrs_dists['no_treatment_nlvo'][-1] + np.sum(mrs_dists['no_treatment_nlvo'][:-1] * 0.011),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a7decb9-4f12-4415-885f-e75bc2b25547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.195822, 0.259118, 0.11868 , 0.126592, 0.146372, 0.061318,\n",
       "       0.092098])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_effect_nlvo_ivt_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3088661d-89a6-4049-963d-77646b2866ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.196 0.259 0.119 0.127 0.146 0.061 0.092]\n"
     ]
    }
   ],
   "source": [
    "no_effect_nlvo_ivt_deaths = fudge_sum_one(no_effect_nlvo_ivt_deaths, dp=3)\n",
    "\n",
    "print(np.round(np.sum(no_effect_nlvo_ivt_deaths), 3), no_effect_nlvo_ivt_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bac84f-d2b5-4dd3-b75b-db7de2852c1d",
   "metadata": {},
   "source": [
    "Store this result in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c060c123-9add-4739-a729-475976dad5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['no_effect_nlvo_ivt_deaths'] = no_effect_nlvo_ivt_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4cc6f-7ab9-45d2-8641-51e06e283305",
   "metadata": {},
   "source": [
    "### LVO treated with IVT at the no-effect time\n",
    "\n",
    "This step uses the excess death rate for IVT which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "![Method for finding mRS distribution for LVO treated with IVT at the no-effect time. 1. Apply excess deaths to “no treatment” distribution. For a population treated at the time of no effect, expect no improvement compared with the no-treatment distribution but for some additional deaths. Assume excess death is equally likely for all patients. → Result: mRS distribution for LVO treated with IVT at the no-effect time.](./images/data_sources_lvo-ivt-no-effect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349ef8a-7126-4d6d-95eb-33018c8c27ef",
   "metadata": {},
   "source": [
    "Calculate the excess deaths by multiplying the no-treatment distribution by 0.034. Subtract the excess deaths from the mRS 0 to 5 bins, and add them on to the mRS=6 bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16dea7e7-717a-4c9f-9b55-7cf875a65ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_effect_lvo_ivt_deaths = np.append(\n",
    "    mrs_dists['no_treatment_lvo'][:-1] * (1.0 - 0.034),\n",
    "    mrs_dists['no_treatment_lvo'][-1] + np.sum(mrs_dists['no_treatment_lvo'][:-1] * 0.034),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e07a3ac0-8d09-469c-952b-496e8cd2dd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0483  , 0.076314, 0.131376, 0.158424, 0.238602, 0.13041 ,\n",
       "       0.216574])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_effect_lvo_ivt_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24a0faba-4b52-45af-98a8-13303bc1fac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.048 0.076 0.131 0.159 0.239 0.13  0.217]\n"
     ]
    }
   ],
   "source": [
    "no_effect_lvo_ivt_deaths = fudge_sum_one(no_effect_lvo_ivt_deaths, dp=3)\n",
    "\n",
    "print(np.round(np.sum(no_effect_lvo_ivt_deaths), 3), no_effect_lvo_ivt_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd1128-45f3-4108-9978-68863b89d7e5",
   "metadata": {},
   "source": [
    "Store this result in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d332da9-549d-41be-b25a-cdc49476d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['no_effect_lvo_ivt_deaths'] = no_effect_lvo_ivt_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b619f18-ced7-41c1-9f4a-4d0c6dd5a49f",
   "metadata": {},
   "source": [
    "### LVO treated with MT at the no-effect time\n",
    "\n",
    "This step uses the excess death rate for IVT which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "![Method for finding mRS distribution for LVO treated with MT at the no-effect time. 1. Apply excess deaths to “no treatment” distribution. For a population treated at the time of no effect, expect no improvement compared with the no-treatment distribution but for some additional deaths. Use the excess death rate of 4.0%. Assume excess death is equally likely for all patients. → Result: mRS distribution for LVO treated with MT at the no-effect time.](./images/data_sources_lvo-mt-no-effect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d87a87-eb6e-4c47-a28f-4b4f5bf8af4e",
   "metadata": {},
   "source": [
    "Calculate the excess deaths by multiplying the no-treatment distribution by 0.040. Subtract the excess deaths from the mRS 0 to 5 bins, and add them on to the mRS=6 bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4e5d67f-1012-464d-b88a-ab80a785c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_effect_lvo_mt_deaths = np.append(\n",
    "    mrs_dists['no_treatment_lvo'][:-1] * (1.0 - 0.040),\n",
    "    mrs_dists['no_treatment_lvo'][-1] + np.sum(mrs_dists['no_treatment_lvo'][:-1] * 0.040),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cef2d08-f2ab-4249-8341-0166b3eb18ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.048  , 0.07584, 0.13056, 0.15744, 0.23712, 0.1296 , 0.22144])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_effect_lvo_mt_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ed5b082-526c-40d6-90ff-0ebfe72622ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.048 0.076 0.131 0.157 0.237 0.13  0.221]\n"
     ]
    }
   ],
   "source": [
    "no_effect_lvo_mt_deaths = fudge_sum_one(no_effect_lvo_mt_deaths, dp=3)\n",
    "\n",
    "print(np.round(np.sum(no_effect_lvo_mt_deaths), 3), no_effect_lvo_mt_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6980765-d3df-4482-ae7a-5d43ed14b629",
   "metadata": {},
   "source": [
    "Store this result in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13cfe320-fa35-41d5-94fd-2d7d21076046",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['no_effect_lvo_mt_deaths'] = no_effect_lvo_mt_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b84c5-c024-4693-9d2b-dfe8ee661b22",
   "metadata": {},
   "source": [
    "## 4. Treatment at time zero\n",
    "\n",
    "### nLVO treated with IVT at time zero\n",
    "\n",
    "This step uses the excess death rate for IVT which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "It also uses a formula for calculating probability at time zero which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "![Method for finding mRS distribution for nLVO treated with IVT at time zero. 1. Get reference probability at no-effect time. Take the probability of mRS being less than or equal to 1. This matches the data that went into the formula for probability at time zero. → P(mRS<=1 | t=t_ne) = 45.5%. 2. Calculate a reference probability at time zero. Plug the values of a and PR=45.5% into the formula. → P(mRS<=1 | t=0) = 64.2%. 3. Combine mRS distributions. To reach P(mRS<=1 | t=0)=0.642 in the time-zero distribution, use the following weighted distributions: Apply the excess deaths to the pre-stroke data. Multiply the “pre-stroke data with excess deaths” data by 0.643. Multiply the “IVT at no-effect time” data by 0.357. Add these two sets of data together. → Result: mRS distribution for nLVO treated with IVT at time zero.](./images/data_sources_nlvo-ivt-time-zero.png)\n",
    "\n",
    "__1. Get reference probability at no-effect time__\n",
    "\n",
    "Sum the probabilities for mRS=0 and mRS=1 at the time of no effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4da6cbd9-3adf-478b-b661-627977df4a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.455"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_mrsleq1_tne = np.sum(mrs_dists['no_effect_nlvo_ivt_deaths'][:2])\n",
    "\n",
    "p_mrsleq1_tne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbd4be-0670-4aa0-8cce-5f6c420a5fc9",
   "metadata": {},
   "source": [
    "__2. Calculate a reference probability at time zero.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2afc5c79-09d9-4ad0-b299-1915e5d1f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.76296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4f2bead-7035-4d7e-96a9-7ef151dcbb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.exp(a) * (p_mrsleq1_tne / (1.0 - p_mrsleq1_tne))\n",
    "p_mrsleq1_t0 = round(t / (1 + t), 3)\n",
    "\n",
    "p_mrsleq1_t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d5e1a-57d3-43cf-a0b4-0454476f1f87",
   "metadata": {},
   "source": [
    "__3. Combine mRS distributions.__\n",
    "\n",
    "Calculate the excess deaths by multiplying the no-treatment distribution by 0.011. Subtract the excess deaths from the mRS 0 to 5 bins, and add them on to the mRS=6 bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "657b4d3e-af21-4f9e-9fb7-d607fb163bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_stroke_nlvo_ivt_deaths = np.append(\n",
    "    mrs_dists['pre_stroke_nlvo'][:-1] * (1.0 - 0.011),\n",
    "    mrs_dists['pre_stroke_nlvo'][-1] + np.sum(mrs_dists['pre_stroke_nlvo'][:-1] * 0.011),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890638d-05e0-47ee-a8d1-4956a40851f6",
   "metadata": {},
   "source": [
    "The time-zero distribution is a weighted combination of the pre-stroke and no-effect distributions.\n",
    "\n",
    "Define these probabilities for mRS <= 1: \n",
    "+ $P_1$ for time-zero,\n",
    "+ $P_2$ for pre-stroke,\n",
    "+ $P_3$ for no-effect.\n",
    "\n",
    "And calculate the weight $w$.\n",
    "\n",
    "The time-zero probability $P_1$ is found by:\n",
    "1. scaling down the no-effect distribution to $(1 - w)$\n",
    "1. scaling down the pre-stroke distribution to $w$\n",
    "2. taking the sum\n",
    "\n",
    "As a formula, this is:\n",
    "\n",
    "$$ P_1 = (1 - w) \\times P_3 + w \\times P_2$$\n",
    "\n",
    "Rearrange to find the weight $w$:\n",
    "\n",
    "$$ w \\times (P_2 - P_3) = P_1 - P_3 $$\n",
    "\n",
    "$$ w = \\frac{P_1 - P_3}{P_2 - P_3} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "707d87e3-5f1b-4853-a0c2-e5f9401630d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p_mrsleq1_t0\n",
    "\n",
    "# Sum the probabilities of mRS=0 and mRS=1 in the pre-stroke dist:\n",
    "p2 = np.sum(mrs_dists['pre_stroke_nlvo'][:2])\n",
    "\n",
    "p3 = p_mrsleq1_tne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4179d17f-aaf7-4be9-9c05-038a20cc252d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6426116838487973"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (p1 - p3) / (p2 - p3)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68793efb-00c3-403b-ba1e-0c4567952dc1",
   "metadata": {},
   "source": [
    "Use this weight to calculate the new distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5aeb28ac-5544-43bb-9bf3-95e5f7173ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44469072, 0.19730928, 0.10936082, 0.1102921 , 0.07916838,\n",
       "       0.02629897, 0.03287973])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_zero_nlvo = (\n",
    "    ((1 - w) * mrs_dists['no_effect_nlvo_ivt_deaths']) + \n",
    "    (w * mrs_dists['pre_stroke_nlvo'])\n",
    ")\n",
    "\n",
    "time_zero_nlvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efdd80-fac0-4b97-87d0-cb70fb955733",
   "metadata": {},
   "source": [
    "Round to the same precision as the no-treatment LVO distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "384d501e-1d35-411e-aee4-6ac9929219d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.445 0.197 0.11  0.11  0.079 0.026 0.033]\n"
     ]
    }
   ],
   "source": [
    "time_zero_nlvo = fudge_sum_one(time_zero_nlvo, dp=3)\n",
    "\n",
    "print(np.round(np.sum(time_zero_nlvo), 3), time_zero_nlvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acaf82c-1f20-41aa-ad56-f908d735f832",
   "metadata": {},
   "source": [
    "Store this result in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "249d76d6-f604-4fff-9cce-a2441f47cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['t0_treatment_nlvo_ivt'] = time_zero_nlvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e96d45b-d348-49ba-8f78-666930d599a1",
   "metadata": {},
   "source": [
    "Check that the mRS <= 1 values sum to the target probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35ecf7ca-941f-43dc-bc7f-2c029ba08d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mrs_dists['t0_treatment_nlvo_ivt'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37da9a-1311-4ce8-ac30-840aa1928b24",
   "metadata": {},
   "source": [
    "Are the values the same to a few decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79241b5f-8dfa-4b3b-a166-f030f9f4e627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(np.sum(mrs_dists['t0_treatment_nlvo_ivt'][:2]), p_mrsleq1_t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d312a25a-ff50-4fdc-a857-bfb0eb4554f7",
   "metadata": {},
   "source": [
    "### LVO treated with IVT at time zero\n",
    "\n",
    "This step uses the excess death rate for IVT which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "It also uses a formula for calculating probability at time zero which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "![Method for finding mRS distribution for LVO treated with IVT at time zero. 1. Get reference probability at no-effect time. Take the probability of mRS being less than or equal to 1. This matches the data that went into the formula for probability at time zero. → P(mRS<=1 | t=t_ne) = 12.4%. 2. Calculate a reference probability at time zero. Plug the values of a and PR=12.4% into the formula. → P(mRS<=1 | t=0) = 23.3%. 3. Combine mRS distributions. To reach P(mRS<=1 | t=0)=0.233 in the time-zero distribution, use the following weighted distributions: Apply the excess deaths to the pre-stroke data. Multiply the “pre-stroke data with excess deaths” data by 0.255. Multiply the “IVT at no-effect time” data by 0.745. Add these two sets of data together. → Result: mRS distribution for LVO treated with IVT at time zero.](./images/data_sources_lvo-ivt-time-zero.png)\n",
    "\n",
    "__1. Get reference probability at no-effect time__\n",
    "\n",
    "Sum the probabilities for mRS=0 and mRS=1 at the time of no effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "322961dd-cd4b-4efa-9e7c-b5d63d0c5650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.124"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_mrsleq1_tne = np.sum(mrs_dists['no_effect_lvo_ivt_deaths'][:2])\n",
    "\n",
    "p_mrsleq1_tne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79572e8d-4657-4e9f-95fa-9c03939c1f65",
   "metadata": {},
   "source": [
    "__2. Calculate a reference probability at time zero.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a56f595-0b95-40c6-bcac-b7162b63c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.76296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5eea8c6c-71ff-4167-93db-c3a49e06e54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.233"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.exp(a) * (p_mrsleq1_tne / (1.0 - p_mrsleq1_tne))\n",
    "p_mrsleq1_t0 = round(t / (1 + t), 3)\n",
    "\n",
    "p_mrsleq1_t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f3ea4-2f1d-4513-bc87-c1d1f4e43605",
   "metadata": {},
   "source": [
    "__3. Combine mRS distributions.__\n",
    "\n",
    "Calculate the excess deaths by multiplying the no-treatment distribution by 0.034. Subtract the excess deaths from the mRS 0 to 5 bins, and add them on to the mRS=6 bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1232e5d2-f2e2-4896-9416-590eefc3e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_stroke_lvo_ivt_deaths = np.append(\n",
    "    mrs_dists['pre_stroke_lvo'][:-1] * (1.0 - 0.034),\n",
    "    mrs_dists['pre_stroke_lvo'][-1] + np.sum(mrs_dists['pre_stroke_lvo'][:-1] * 0.034),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca7714-b521-4712-8588-d57e6f554efe",
   "metadata": {},
   "source": [
    "The time-zero distribution is a weighted combination of the pre-stroke and no-effect distributions.\n",
    "\n",
    "Define these probabilities for mRS <= 1: \n",
    "+ $P_1$ for time-zero,\n",
    "+ $P_2$ for pre-stroke,\n",
    "+ $P_3$ for no-effect.\n",
    "\n",
    "And calculate the weight $w$.\n",
    "\n",
    "The time-zero probability $P_1$ is found by:\n",
    "1. scaling down the no-effect distribution to $(1 - w)$\n",
    "1. scaling down the pre-stroke distribution to $w$\n",
    "2. taking the sum\n",
    "\n",
    "As a formula, this is:\n",
    "\n",
    "$$ P_1 = (1 - w) \\times P_3 + w \\times P_2$$\n",
    "\n",
    "Rearrange to find the weight $w$:\n",
    "\n",
    "$$ w \\times (P_2 - P_3) = P_1 - P_3 $$\n",
    "\n",
    "$$ w = \\frac{P_1 - P_3}{P_2 - P_3} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "897cba5b-e5ef-4913-9e54-e6faab207ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p_mrsleq1_t0\n",
    "\n",
    "# Sum the probabilities of mRS=0 and mRS=1 in the pre-stroke dist:\n",
    "p2 = np.sum(mrs_dists['pre_stroke_lvo'][:2])\n",
    "\n",
    "p3 = p_mrsleq1_tne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0357166-1034-43e1-a1c3-9588d51ac337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25467289719626174"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (p1 - p3) / (p2 - p3)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48843b-ee09-41f2-9945-d0c01ee0f4bb",
   "metadata": {},
   "source": [
    "Use this weight to calculate the new distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a2fe350-1d1b-4ffb-a257-61f5ba5f276c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13968224, 0.09331776, 0.1281986 , 0.16078271, 0.20818458,\n",
       "       0.10809813, 0.16173598])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_zero_lvo = (\n",
    "    ((1 - w) * mrs_dists['no_effect_lvo_ivt_deaths']) +\n",
    "    (w * mrs_dists['pre_stroke_lvo'])\n",
    ")\n",
    "\n",
    "time_zero_lvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65342654-7a26-4461-a54d-a96e13868825",
   "metadata": {},
   "source": [
    "Round to the same precision as the no-treatment LVO distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46015c57-f72a-448e-8642-600c71d17b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.14  0.093 0.128 0.161 0.208 0.108 0.162]\n"
     ]
    }
   ],
   "source": [
    "time_zero_lvo = fudge_sum_one(time_zero_lvo, dp=3)\n",
    "\n",
    "print(np.round(np.sum(time_zero_lvo), 3), time_zero_lvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7619e2-3e8a-4a65-a303-613837bfc275",
   "metadata": {},
   "source": [
    "Store this result in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "387ecd06-da35-42a4-af1b-c2bbd0228482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['t0_treatment_lvo_ivt'] = time_zero_lvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b718c2-18e5-43d3-b619-d5ea80fddfec",
   "metadata": {},
   "source": [
    "Check that the mRS <= 1 values sum to the target probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55d155bf-2a49-4070-8897-ce799ae60f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.233"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mrs_dists['t0_treatment_lvo_ivt'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473cb84a-4508-4ddb-b91a-b06793ad7239",
   "metadata": {},
   "source": [
    "Are the values the same to a few decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58bc3d30-7b4a-440d-bdef-aef83f6e5ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(np.sum(mrs_dists['t0_treatment_lvo_ivt'][:2]), p_mrsleq1_t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd1b0d-aa6b-4367-aedd-81c00807b3f3",
   "metadata": {},
   "source": [
    "### LVO treated with MT at time zero\n",
    "\n",
    "This step uses the excess death rate for IVT which is calculated in this document. __TO DO: ADD LINK__\n",
    "\n",
    "![Method for finding mRS distribution for LVO treated with MT at time zero. 1. Define time-zero distribution. Combine 75% of the full-effect data with 25% of the no-effect data. The full-effect data is the pre-stroke data with the excess deaths as a result of MT. 2. Add excess deaths to pre-stroke distribution. 3. Combine the data for full effect and no effect of recanalisation. Multiply the “LVO pre-stroke with excess deaths” data by 0.75. Multiply the “LVO MT at no-effect time” data by 0.25. Add these two sets of data together. → Result: mRS distribution for LVO treated with MT at time zero.](./images/data_sources_lvo-mt-time-zero.png)\n",
    "\n",
    "__2. Add excess deaths to pre-stroke distribution.__\n",
    "\n",
    "Calculate the excess deaths by multiplying the no-treatment distribution by 0.040. Subtract the excess deaths from the mRS 0 to 5 bins, and add them on to the mRS=6 bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af183437-0e87-41b8-a639-1b76379f5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_stroke_lvo_mt_deaths = np.append(\n",
    "    mrs_dists['pre_stroke_lvo'][:-1] * (1.0 - 0.040),\n",
    "    mrs_dists['pre_stroke_lvo'][-1] + np.sum(mrs_dists['pre_stroke_lvo'][:-1] * 0.040),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a3c3434-0e34-48f8-bc44-17ad4bda8f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.392 0.138 0.115 0.16  0.113 0.042 0.04 ]\n"
     ]
    }
   ],
   "source": [
    "pre_stroke_lvo_mt_deaths = fudge_sum_one(pre_stroke_lvo_mt_deaths, dp=3)\n",
    "\n",
    "print(np.round(np.sum(pre_stroke_lvo_mt_deaths), 3), pre_stroke_lvo_mt_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1930e8f-c182-4a2d-b7d6-5df96b65bfd3",
   "metadata": {},
   "source": [
    "__3. Combine the data for full effect and no effect of recanalisation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e749c597-0213-463b-b2e9-56c83eb3e23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.306  , 0.1225 , 0.119  , 0.15925, 0.144  , 0.064  , 0.08525])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_zero_lvo_mt = (\n",
    "    (0.75 * pre_stroke_lvo_mt_deaths) +\n",
    "    (0.25 * mrs_dists['no_effect_lvo_mt_deaths'])\n",
    ")\n",
    "\n",
    "time_zero_lvo_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0bad2a9-2d8e-4969-b2f3-84e11ccca01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [0.306 0.123 0.119 0.159 0.144 0.064 0.085]\n"
     ]
    }
   ],
   "source": [
    "time_zero_lvo_mt = fudge_sum_one(time_zero_lvo_mt, dp=3)\n",
    "\n",
    "print(np.round(np.sum(time_zero_lvo_mt), 3), time_zero_lvo_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c6449-f9c3-4922-bbc7-1244544897f1",
   "metadata": {},
   "source": [
    "Store this result in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18e1014a-4736-4dea-b722-b2ad1c4b8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrs_dists['t0_treatment_lvo_mt'] = time_zero_lvo_mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b2843-d275-412f-9c56-e43d72f10e31",
   "metadata": {},
   "source": [
    "### Sanity check for recanalisation rate\n",
    "\n",
    "![Sanity check for MT success rate. 1. Extrapolate the line back to time zero. End points from the graph (given in “Tertiary analysis” section): Assume the decrease with time is constant and that the graph shows a straight line. This gives an average decrease in probability of 4.8% per hour. At time zero, the probability would be 55% + (3 x 4.8%) = 69.4%. Pre-stroke probability of mRS 0-2 is: 0.408+0.144+0.120 = 67.2%. → for successful recanalisation, use the full recovery mRS distribution. 2. Check treatment at 8 hours. From the graph, the end point is 31%. Scaling down by 0.75 successful recanalisation gives 31% x 0.75 = 23.25%. Probability of mRS 0-2 given MT at time of no effect (8 hours) is 0.048 + 0.076 + 0.131 = 25.5%. 3. Check treatment at 0 hours. From the graph, the extrapolated point at time zero is 69.4%. Scaling down by 0.75 successful recanalisation rate, 69.4% x 0.75 = 52.05%. MT at time zero probability of mRS 0-2 is: 0.306 + 0.123 + 0.119 = 54.8%. → 75% successful recanalisation gives a good enough match.](./images/data_sources_sanity_mt-success-rate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27912e38-0cb7-42fa-869b-4b3ac2d2ecfe",
   "metadata": {},
   "source": [
    "## Result - all distributions\n",
    "\n",
    "Firstly create a DataFrame of the non-cumulative mRS distributions. Each entry has a value for mRS=0, mRS=1, ..., mRS=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "923ef888-2abd-4048-9a1e-8b29c5fe238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre_stroke_nlvo</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_stroke_lvo</th>\n",
       "      <td>0.408</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_treatment_lvo</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_treatment_nlvo</th>\n",
       "      <td>0.198</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_effect_nlvo_ivt_deaths</th>\n",
       "      <td>0.196</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_effect_lvo_ivt_deaths</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_effect_lvo_mt_deaths</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0_treatment_nlvo_ivt</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0_treatment_lvo_ivt</th>\n",
       "      <td>0.140</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0_treatment_lvo_mt</th>\n",
       "      <td>0.306</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0      1      2      3      4      5      6\n",
       "pre_stroke_nlvo            0.583  0.163  0.104  0.101  0.042  0.007  0.000\n",
       "pre_stroke_lvo             0.408  0.144  0.120  0.166  0.118  0.044  0.000\n",
       "no_treatment_lvo           0.050  0.079  0.136  0.164  0.247  0.135  0.189\n",
       "no_treatment_nlvo          0.198  0.262  0.120  0.128  0.148  0.062  0.082\n",
       "no_effect_nlvo_ivt_deaths  0.196  0.259  0.119  0.127  0.146  0.061  0.092\n",
       "no_effect_lvo_ivt_deaths   0.048  0.076  0.131  0.159  0.239  0.130  0.217\n",
       "no_effect_lvo_mt_deaths    0.048  0.076  0.131  0.157  0.237  0.130  0.221\n",
       "t0_treatment_nlvo_ivt      0.445  0.197  0.110  0.110  0.079  0.026  0.033\n",
       "t0_treatment_lvo_ivt       0.140  0.093  0.128  0.161  0.208  0.108  0.162\n",
       "t0_treatment_lvo_mt        0.306  0.123  0.119  0.159  0.144  0.064  0.085"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dists = pd.DataFrame(\n",
    "    np.stack(list(mrs_dists.values()), axis=-1),\n",
    "    columns=list(mrs_dists.keys())\n",
    ").T\n",
    "\n",
    "df_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdad463-b884-4b1f-9983-4b5e81da0081",
   "metadata": {},
   "source": [
    "Then create a DataFrame of the cumulative mRS distributions. Each entry has a value for mRS<=0, mRS<=1, ..., mRS<=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7a62958-c303-4e8e-bb8a-21d1152acb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre_stroke_nlvo</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_stroke_lvo</th>\n",
       "      <td>0.408</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.956</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_treatment_lvo</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.811</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_treatment_nlvo</th>\n",
       "      <td>0.198</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_effect_nlvo_ivt_deaths</th>\n",
       "      <td>0.196</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_effect_lvo_ivt_deaths</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.783</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_effect_lvo_mt_deaths</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.779</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0_treatment_nlvo_ivt</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.967</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0_treatment_lvo_ivt</th>\n",
       "      <td>0.140</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.838</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0_treatment_lvo_mt</th>\n",
       "      <td>0.306</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0      1      2      3      4      5    6\n",
       "pre_stroke_nlvo            0.583  0.746  0.850  0.951  0.993  1.000  1.0\n",
       "pre_stroke_lvo             0.408  0.552  0.672  0.838  0.956  1.000  1.0\n",
       "no_treatment_lvo           0.050  0.129  0.265  0.429  0.676  0.811  1.0\n",
       "no_treatment_nlvo          0.198  0.460  0.580  0.708  0.856  0.918  1.0\n",
       "no_effect_nlvo_ivt_deaths  0.196  0.455  0.574  0.701  0.847  0.908  1.0\n",
       "no_effect_lvo_ivt_deaths   0.048  0.124  0.255  0.414  0.653  0.783  1.0\n",
       "no_effect_lvo_mt_deaths    0.048  0.124  0.255  0.412  0.649  0.779  1.0\n",
       "t0_treatment_nlvo_ivt      0.445  0.642  0.752  0.862  0.941  0.967  1.0\n",
       "t0_treatment_lvo_ivt       0.140  0.233  0.361  0.522  0.730  0.838  1.0\n",
       "t0_treatment_lvo_mt        0.306  0.429  0.548  0.707  0.851  0.915  1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dists_cumulative = pd.DataFrame(\n",
    "    np.cumsum(np.stack(list(mrs_dists.values()), axis=-1), axis=0),\n",
    "    columns=list(mrs_dists.keys())\n",
    ").T\n",
    "\n",
    "df_dists_cumulative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796df838-0d31-4de6-bf1f-8dc930aaab65",
   "metadata": {},
   "source": [
    "Save these derived mRS distributions to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a19f26d-7bc8-4a8d-aef8-ee44b18527c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dists.to_csv('./mrs_dists.csv')\n",
    "df_dists_cumulative.to_csv('./mrs_dists_cumulative.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
